"""
VISUALIZE EMBEDDINGS & VECTOR DATABASE
========================================
Shows how embeddings are stored and how retrieval works.

Your Database: CHROMA
- Local, persistent vector storage
- Stores 1,564 embeddings (384 dimensions each)
- Located in: data/chroma_db/
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.index import get_collection
from src.embed import embed_single_chunk
from src.retrieve import retrieve
import numpy as np

print("\n" + "â–ˆ"*80)
print("â–ˆ" + " "*78 + "â–ˆ")
print("â–ˆ" + " "*20 + "EMBEDDINGS & VECTOR DATABASE VISUALIZATION" + " "*18 + "â–ˆ")
print("â–ˆ" + " "*78 + "â–ˆ")
print("â–ˆ"*80)

print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘  YOUR VECTOR DATABASE: CHROMA                                               â•‘
â•‘                                                                              â•‘
â•‘  What is a Vector Database?                                                 â•‘
â•‘  â”Œâ”€ Normal database: stores text, numbers, dates (SQL)                     â•‘
â•‘  â”œâ”€ Vector database: stores embeddings (vectors)                           â•‘
â•‘  â”œâ”€ Can do: similarity search (find similar documents)                     â•‘
â•‘  â””â”€ Uses math: cosine distance, euclidean distance, etc.                   â•‘
â•‘                                                                              â•‘
â•‘  Chroma Advantages:                                                         â•‘
â•‘  âœ“ Local: runs on your machine, no cloud                                   â•‘
â•‘  âœ“ Persistent: data saved to disk (data/chroma_db/)                        â•‘
â•‘  âœ“ Simple: no configuration needed                                          â•‘
â•‘  âœ“ Fast: instant similarity search                                         â•‘
â•‘  âœ“ Cost: free (no API calls)                                               â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

print(f"\n1ï¸âƒ£  CHROMA DATABASE CONTENTS")
print("â”€" * 80)

# Get the collection
collection = get_collection()

if not collection:
    print("âŒ Chroma database not found. Run: python scripts/ingest.py first")
    sys.exit(1)

# Get collection stats
count = collection.count()
print(f"âœ… Database Status: ACTIVE")
print(f"   Location: data/chroma_db/")
print(f"   Total chunks stored: {count}")
print(f"   Embedding dimensions: 384")
print(f"   Embedding model: sentence-transformers/all-MiniLM-L6-v2")

print(f"\n2ï¸âƒ£  EMBEDDING STRUCTURE")
print("â”€" * 80)

print(f"""
   Each chunk is stored as:

   â”Œâ”€ ID: "chunk_0", "chunk_1", ..., "chunk_1563"
   â”œâ”€ Text: Full chunk text (invoice info + service details)
   â”œâ”€ Embedding: 384 numbers (vector)
   â”‚   Example: [-0.123, 0.456, -0.789, ... (381 more numbers)]
   â”œâ”€ Metadata:
   â”‚   â”œâ”€ invoice_id
   â”‚   â”œâ”€ date
   â”‚   â”œâ”€ customer_name
   â”‚   â”œâ”€ vehicle_year
   â”‚   â”œâ”€ vehicle_make
   â”‚   â”œâ”€ vehicle_model
   â”‚   â”œâ”€ vin
   â”‚   â””â”€ mileage
   â””â”€ Ready for: semantic search!

   Why 384 dimensions?
   - Trade-off: quality vs speed
   - 384 captures semantic meaning well
   - Small enough for fast search
   - The magic of sentence-transformers
""")

print(f"\n3ï¸âƒ£  HOW SIMILARITY SEARCH WORKS")
print("â”€" * 80)

print(f"""
   Process:
   1. User asks: "What brake problems?"

   2. Embed the query (same model as chunks)
      "What brake problems?" â†’ [-0.234, 0.567, ..., 384 numbers]

   3. Compare query vector to all 1,564 chunk vectors
      Using COSINE SIMILARITY:
      similarity = dot_product(query_vec, chunk_vec) / (norm1 * norm2)
      Result: 0 to 1 (0=completely different, 1=identical)

   4. Sort by similarity descending
      Chunk A: 0.82
      Chunk B: 0.79
      Chunk C: 0.76
      Chunk D: 0.71
      Chunk E: 0.68

   5. Return top-5 (default K=5)
      These 5 chunks are most similar to query!

   Time: <1 millisecond for all 1,564 searches!
""")

print(f"\n4ï¸âƒ£  LIVE SIMILARITY SEARCH DEMO")
print("â”€" * 80)

test_queries = [
    "What electrical problems?",
    "Brake repairs and maintenance",
    "Engine troubles",
]

for query in test_queries:
    print(f"\nğŸ” Query: \"{query}\"")
    print(f"   Searching 1,564 chunks...")

    results = retrieve(query, k=3)

    if results:
        print(f"   âœ… Top 3 Results:\n")
        for i, chunk in enumerate(results, 1):
            similarity_percent = chunk['similarity'] * 100
            print(f"   [{i}] Similarity: {similarity_percent:.1f}%")
            print(f"       Invoice: {chunk['metadata'].get('invoice_id')}")
            print(f"       Snippet: {chunk['text'].split(chr(10))[7][:50]}...")

print(f"\n5ï¸âƒ£  EMBEDDING VECTOR SPACE (CONCEPTUAL)")
print("â”€" * 80)

print(f"""
   Your 1,564 chunks live in 384-dimensional space.

   Conceptually (if we could visualize 384D!):

   ELECTRICAL CHUNK REGION:
   â”œâ”€ chunk_42: "replaced wiring"
   â”œâ”€ chunk_107: "fixed lighting"
   â”œâ”€ chunk_89: "repaired circuit"
   â””â”€ All close together in vector space!

   BRAKE CHUNK REGION:
   â”œâ”€ chunk_156: "replaced brake shoes"
   â”œâ”€ chunk_203: "brake fluid"
   â””â”€ All close together in vector space!

   TRANSMISSION CHUNK REGION:
   â”œâ”€ chunk_300: "transmission replaced"
   â”œâ”€ chunk_445: "shift problems"
   â””â”€ All close together in vector space!

   When you search "electrical":
   - Query embeds close to ELECTRICAL REGION
   - Finds nearby chunks
   - Returns electrical repairs! âœ“

   This is the power of semantic embeddings!
""")

print(f"\n6ï¸âƒ£  VECTOR DATABASE INTERNALS")
print("â”€" * 80)

print(f"""
   Behind the scenes, Chroma uses:

   â”Œâ”€ DuckDB: SQL database for metadata
   â”œâ”€ HNSW: Hierarchical Navigable Small World (fast search)
   â”œâ”€ Vector indexing: Organizes 384D vectors for quick lookup
   â””â”€ Cosine distance: Metric for similarity

   File Structure:
   data/chroma_db/
   â”œâ”€ chroma.sqlite3          (metadata: invoice IDs, dates, etc.)
   â”œâ”€ chroma-embeddings/      (the vector indices)
   â”‚  â”œâ”€ segment_data/        (actual embeddings stored here)
   â”‚  â””â”€ index/               (HNSW index for fast search)
   â””â”€ other files             (Chroma internals)

   Total size: ~50 MB for 1,564 embeddings
   Search time: <1 millisecond per query
""")

print(f"\n7ï¸âƒ£  RETRIEVAL PIPELINE VISUALIZATION")
print("â”€" * 80)

print(f"""
   Complete flow:

   User Input
   â”‚
   v
   Query: "What brake problems?"
   â”‚
   v
   Embed Query (384 dimensions)
   â”œâ”€ Model: sentence-transformers
   â””â”€ Output: [-0.234, 0.567, ..., 384 numbers]
   â”‚
   v
   Search Chroma Database
   â”œâ”€ Vector Index (HNSW)
   â”œâ”€ Compare to 1,564 chunk vectors
   â””â”€ Calculate similarity scores
   â”‚
   v
   Rank Results by Similarity
   â”œâ”€ chunk_156: 0.85
   â”œâ”€ chunk_203: 0.82
   â”œâ”€ chunk_300: 0.79
   â”œâ”€ chunk_42:  0.76
   â””â”€ chunk_89:  0.73
   â”‚
   v
   Return Top-K (K=5)
   â”œâ”€ With text
   â”œâ”€ With metadata
   â”œâ”€ With similarity scores
   â””â”€ Ready for generation!
   â”‚
   v
   Claude Reads Retrieved Context
   â””â”€ Generates grounded answer
""")

print(f"\n{'â•' * 80}")
print(f"\nğŸ’¡ KEY INSIGHTS:")
print(f"""
   1. Vector embeddings capture MEANING
      - "brake shoe" and "brake pad" are close in vector space
      - Both match "brake problems" query
      - Different keywords, same meaning âœ“

   2. Chroma is FAST because:
      - HNSW index doesn't check all 1,564 vectors
      - Hierarchical structure skips far-away regions
      - Result: <1ms per query instead of searching all

   3. Similarity score (0-1) shows relevance:
      - 0.95+: Perfect match
      - 0.80-0.95: Highly relevant
      - 0.60-0.80: Somewhat relevant
      - <0.60: Probably not what you want

   4. Why Chroma over alternatives?
      - Pinecone: Cloud, costs money, API limits
      - Weaviate: Overkill for this use case
      - Milvus: Too complex to set up
      - Chroma: Perfect balance âœ“
""")
print(f"{'â•' * 80}\n")
